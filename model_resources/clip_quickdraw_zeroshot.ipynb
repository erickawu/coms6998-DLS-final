{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"clip_quickdraw_zeroshot.ipynb","provenance":[],"authorship_tag":"ABX9TyMf4Mp2IWPQiTQyEOsI7hvu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8pWcJLs3dd3","executionInfo":{"status":"ok","timestamp":1618809045072,"user_tz":240,"elapsed":398,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"eaeb1a5f-1caa-4d11-9a24-b6c2414cee2e"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","root = \"/content/drive/MyDrive/DLFinalProject/\""],"execution_count":34,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S9H0k1fJz9Ls"},"source":["# unpack data from npy files into folders (trial of 5000 samples per 10 classes)\n","# in total, quickdraw has 345 classes\n","img_array = np.load(root + 'data/apple.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"3SDCpMEb0EFm","executionInfo":{"status":"ok","timestamp":1618805382522,"user_tz":240,"elapsed":2731,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"b6758770-4738-48ca-b4ec-614e7cf1846c"},"source":["# reformat data and create tokenizations for CLIP\n","from matplotlib import pyplot as plt\n","\n","plt.imshow(img_array[0].reshape(28,28), cmap='gray')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"9hpJQCUz2FuB"},"source":["CLIP!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OT91VVD2APo","executionInfo":{"status":"ok","timestamp":1618809050300,"user_tz":240,"elapsed":3284,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"f85e62db-4c4d-456f-c898-e6831a29b559"},"source":["# installation dependencies (run this first, then restart kernel)\n","import subprocess\n","\n","CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n","print(\"CUDA version:\", CUDA_version)\n","\n","if CUDA_version == \"10.0\":\n","    torch_version_suffix = \"+cu100\"\n","elif CUDA_version == \"10.1\":\n","    torch_version_suffix = \"+cu101\"\n","elif CUDA_version == \"10.2\":\n","    torch_version_suffix = \"\"\n","else:\n","    torch_version_suffix = \"+cu110\"\n","\n","!pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n","\n","print(\"Torch version:\", torch.__version__)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["CUDA version: 11.0\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Requirement already satisfied: torch==1.7.1+cu110 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu110)\n","Requirement already satisfied: torchvision==0.8.2+cu110 in /usr/local/lib/python3.7/dist-packages (0.8.2+cu110)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n","Torch version: 1.7.1+cu110\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"45-pBpAQ2JJ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618805371834,"user_tz":240,"elapsed":558,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"03b8a669-adb8-4dce-c142-126aafd47a08"},"source":["# clone\n","!git clone https://github.com/openai/CLIP.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'CLIP' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SsHPTLmt2Nkl","executionInfo":{"status":"ok","timestamp":1618809056051,"user_tz":240,"elapsed":216,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}}},"source":["from CLIP import clip\n","from PIL import Image\n","import numpy as np\n","import torch\n","import os"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8hq4ojk5QLT","executionInfo":{"status":"ok","timestamp":1618809056846,"user_tz":240,"elapsed":231,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"a1439720-7783-4101-fe2d-4dfeb44584b4"},"source":["clip.available_models()"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['RN50', 'RN101', 'RN50x4', 'ViT-B/32']"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"0lK8eIuL5eWZ","executionInfo":{"status":"ok","timestamp":1618809061751,"user_tz":240,"elapsed":1753,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}}},"source":["# load model\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# ViT-B/32 works with 224x224 img \n","test_model, transform = clip.load(\"ViT-B/32\", device=device)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"lC3I5R1O7KZh","executionInfo":{"status":"ok","timestamp":1618809064241,"user_tz":240,"elapsed":201,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}}},"source":["# get list of class names\n","class_names = []\n","with open(root + 'data/100categories.txt') as f:\n","    class_names = f.read().splitlines()\n","target_names = [\"a sketch of \" + cls for cls in class_names]"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589},"id":"cmL-6V_z6TyI","executionInfo":{"status":"error","timestamp":1618809087885,"user_tz":240,"elapsed":6450,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"7f327c82-dcbc-4d73-c660-d416fb5c74ff"},"source":["# attempt to classify and look @ accuracy\n","correct = []\n","\n","def argmax(iterable):\n","    return max(enumerate(iterable), key=lambda x: x[1])[0]\n","\n","# define target text classifications\n","class_text_tokens = clip.tokenize(target_names).to(device)\n","\n","for cls in class_names:\n","    class_correct = []\n","    class_img_array = np.load(root + 'data/' + cls + '.npy')\n","    for img in class_img_array[:50]:\n","        pil_img = Image.fromarray(img.reshape((28,28)), 'L')\n","        image = transform(pil_img).unsqueeze(0)\n","        with torch.no_grad():\n","          # encode image and then encode text\n","            # image_features = test_model.encode_image(image).to(device)\n","            # text_features = test_model.encode_text(class_text_tokens).to(device)\n","            # get probs\n","            logits_per_image, logits_per_text = test_model(image, class_text_tokens)\n","            probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","            # make prediction \n","            pred = class_names[argmax(list(probs)[0])]\n","            if pred == cls:\n","                correct.append(1)\n","                class_correct.append(1)\n","            else:\n","                correct.append(0)\n","                class_correct.append(0)\n","    \n","    print('accuracy on class ' + cls + ' is: ' + str(sum(class_correct)/len(class_correct)))\n","print('accuracy on all is: ' + str(sum(correct)/len(correct)))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["tensor([[21.8750, 19.4688, 22.4219, 19.0312, 21.5469, 21.8906, 23.7031, 20.6719,\n","         20.7656, 21.3594, 21.8125, 23.8438, 21.6719, 22.0312, 22.0312, 21.2969,\n","         22.9375, 19.4688, 22.1250, 22.3125, 21.9844, 21.5000, 20.9219, 20.0000,\n","         20.0156, 23.0781, 20.8281, 19.3750, 18.1250, 20.4844, 20.7344, 20.9688,\n","         21.9062, 22.2031, 20.1250, 23.4062, 20.3906, 20.7344, 20.6094, 20.7344,\n","         24.8125, 19.8281, 19.8594, 22.9375, 20.5938, 21.3125, 20.6562, 20.8438,\n","         20.0000, 19.8281, 21.6875, 19.4844, 20.4375, 21.2969, 21.7031, 20.1094,\n","         21.1094, 20.3906, 20.4688, 20.5469, 22.1094, 21.3906, 21.3906, 20.5000,\n","         21.2500, 22.9375, 24.8594, 20.0938, 21.9219, 21.3125, 20.5469, 22.3594,\n","         20.3594, 22.2188, 20.9219, 21.5469, 20.2031, 22.9375, 22.5781, 20.0781,\n","         19.4531, 20.0469, 21.1250, 20.7969, 22.6250, 20.3281, 20.8750, 20.6094,\n","         20.1250, 20.8438, 20.3750, 20.5938, 21.6719, 20.8125, 18.9375, 20.9375,\n","         19.1094, 21.7812, 19.8125, 21.7031]], device='cuda:0',\n","       dtype=torch.float16)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-4f105629feb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# text_features = test_model.encode_text(class_text_tokens).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# get probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlogits_per_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_per_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_text_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_per_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_per_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Q6QYW1pVgPr","executionInfo":{"status":"ok","timestamp":1618805703849,"user_tz":240,"elapsed":214,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"15602170-8de6-48ac-8e21-32d2f0b62b73"},"source":["print(class_text_tokens[5])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([49406,   320,  5269,   539, 16637, 49407,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MIMa6ZZYbOcT"},"source":["Fine-Tuning CLIP"]},{"cell_type":"code","metadata":{"id":"0fcGGnu4G5D6","executionInfo":{"status":"ok","timestamp":1618809091608,"user_tz":240,"elapsed":235,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}}},"source":["# functions to load in data and construct pytorch dataloader \n","def load_dataset(root, mtype):\n","    num_classes = 100\n","\n","    if os.path.exists(os.path.join(root, mtype+'.npz')):\n","        print(\"*\"*50)\n","        print(\"Loading \"+mtype+\" dataset...\")\n","        print(\"*\"*50)\n","        print(\"Classes number of \"+mtype+\" dataset: \"+str(num_classes))\n","        print(\"*\"*50)\n","        data_cache = np.load(os.path.join(root, mtype+'.npz'))\n","        return data_cache[\"data\"].astype('float32'), \\\n","            data_cache[\"target\"].astype('int64'), num_classes\n","    \n","    else:\n","        raise FileNotFoundError(\"%s doesn't exist!\" %\n","                                os.path.join(root, mtype+'.npz'))\n","\n","class QD_Dataset(torch.utils.data.Dataset):\n","    def __init__(self, mtype, root):\n","        \"\"\"\n","        args:\n","        - mytpe: str, specify the type of the dataset, i.e, 'train' or 'test'\n","        - root: str, specify the root of the dataset directory\n","        \"\"\"\n","        self.data, self.target, self.num_classes = load_dataset(root, mtype)\n","        print(\"dataset \"+mtype+\" loading done.\")\n","        print(\"*\"*50+\"\\n\")\n","\n","    def __getitem__(self, index):\n","        curr = self.data[index]\n","        pil_img = Image.fromarray(curr.reshape((28,28)), 'L')\n","        pil_img = transform(pil_img)\n","        caption = \"a sketch of \" + class_names[self.target[index]]\n","        return pil_img, caption\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def get_number_classes(self):\n","        return self.num_classes"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfaRX2k_Zt78","executionInfo":{"status":"ok","timestamp":1618809102831,"user_tz":240,"elapsed":9475,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"d7ef1948-d6bc-485d-8a4c-a5df2d36bed4"},"source":["train_dataset = QD_Dataset(mtype = \"train\", root=root+\"data/datasets\")"],"execution_count":43,"outputs":[{"output_type":"stream","text":["**************************************************\n","Loading train dataset...\n","**************************************************\n","Classes number of train dataset: 100\n","**************************************************\n","dataset train loading done.\n","**************************************************\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w8cXgeRbageR","executionInfo":{"status":"ok","timestamp":1618809102832,"user_tz":240,"elapsed":8824,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}}},"source":["# 400,000 images (400 per class in training) (the other 100 in test!)\n","# class_names array maps from index to class name\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ruDUIU6WVde","executionInfo":{"status":"ok","timestamp":1618809107392,"user_tz":240,"elapsed":12783,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}}},"source":["test_model, transform = clip.load(\"ViT-B/32\", device='cuda', jit=False)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"puc2wXdvUrfx","executionInfo":{"status":"ok","timestamp":1618809271605,"user_tz":240,"elapsed":214,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}}},"source":["# freeze first n layers\n","def freeze(model, num_layers_to_freeze):\n","  ct = 0\n","  for child in model.children():\n","    ct += 1\n","    if ct < num_layers_to_freeze:\n","        for param in child.parameters():\n","            param.requires_grad = False\n","\n","# train function\n","def finetune_CLIP(model, train_loader, num_epochs):\n","  model.train()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=5e-5,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) #Params from paper\n","  loss_img = torch.nn.CrossEntropyLoss()\n","  loss_txt = torch.nn.CrossEntropyLoss()\n","  loss_epoch = 0\n","  for e in range(num_epochs):\n","    for i, (inputs, labels) in enumerate(train_loader):\n","      optimizer.zero_grad()\n","      # get img and text features\n","      images = torch.stack([img for img in inputs], dim=0).to(device)\n","      text_features = clip.tokenize(labels).to(device)\n","      # get logit outputs\n","      logits_per_image, logits_per_text = model(images, text_features)\n","      # get ground truth\n","      ground_truth = torch.arange(inputs.size(0)).long().to(device)\n","      # compute loss\n","      total_loss = (loss_img(logits_per_image, ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n","      loss_epoch += total_loss.item()\n","      total_loss.backward()\n","      optimizer.step()\n","      if ((i+1) % 100) == 0:\n","        print(total_loss.item())\n","    print(\"Epoch %d, Loss: %f\" % (e+1, loss_epoch/len(trainloader)))\n","    # reset loss every epoch\n","    loss_epoch = 0\n","  print(\"Finished training!\")"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXDwWHghb-3V"},"source":["# freeze language transformer?\n","for k in test_model.transformer.parameters():  \n","  k.requires_grad=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5FqGCjlKi9Ka","executionInfo":{"status":"ok","timestamp":1618809184082,"user_tz":240,"elapsed":244,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}}},"source":["def argmax(iterable):\n","    return max(enumerate(iterable), key=lambda x: x[1])[0]"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"FgY9-jfycZjD","colab":{"base_uri":"https://localhost:8080/","height":477},"executionInfo":{"status":"error","timestamp":1618809662860,"user_tz":240,"elapsed":386201,"user":{"displayName":"Ericka Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh16kwJgWVswXGZeTRdmSbxPZth2-yB0bdCDr4R=s64","userId":"11564995692578738679"}},"outputId":"da490561-e5e1-47f8-9ce5-8cc9792bec43"},"source":["finetune_CLIP(test_model, train_loader, 5)"],"execution_count":52,"outputs":[{"output_type":"stream","text":["4.16015625\n","4.16015625\n","4.16015625\n","4.17578125\n","4.15625\n","4.15625\n","4.16015625\n","4.16015625\n","4.15625\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-573f1b419c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinetune_CLIP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-51-13029e7ca59e>\u001b[0m in \u001b[0;36mfinetune_CLIP\u001b[0;34m(model, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_per_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_per_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mloss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 13.40 GiB already allocated; 19.75 MiB free; 13.69 GiB reserved in total by PyTorch)"]}]}]}